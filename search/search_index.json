{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"remotebmi","text":"<p>With remotebmi you can communicate to models using the Basic Model Interface using a  RESTful API. The REST API specification uses the OpenAPI format.</p> <p>Documentation for the implementations in specific languages are available separately:</p> <ul> <li>Python</li> <li>Julia</li> <li>R</li> </ul>"},{"location":"#quick-start","title":"Quick start","text":""},{"location":"#python-consumer","title":"Python consumer","text":"<p>Installation</p> <pre><code>pip install remotebmi\n</code></pre> <p>A client can connect to a running server with the following code.</p> <pre><code>from remotebmi import RemoteBmiClient\n\nmodel = RemoteBmiClient('http://localhost:50051')\n# Now you can use the BMI methods on model\n# for example\nmodel.initialize('config.file')\nmodel.update()\nmodel.get_value('var_name')\n</code></pre> <p>A client can also start a Apptainer container containing the model and the server.</p> <pre><code>from remotebmi import BmiClientApptainer\n\nmodel = BmiClientApptainer('my_model.sif', work_dir='/tmp')\n</code></pre> <p>The client picks a random port and expects the container to run the BMI web server on that port. The port is passed to the container using the <code>BMI_PORT</code> environment variable.</p> <p>A client can also start a Docker container containing the model and the server.</p> <pre><code>from remotebmi import BmiClientDocker\n\nmodel = BmiClientDocker('ewatercycle/wflowjl:0.7.3', work_dir='/tmp')\n</code></pre> <p>The BMI web server inside the Docker container should be running on port 50051. If the port is different, you can pass the port as the <code>image_port</code> argument to the <code>BmiClientDocker</code> constructor.</p>"},{"location":"#python-provider","title":"Python provider","text":"<p>Given you have a model class called <code>MyModel</code> in a package <code>mypackage</code> then the web service can be started with the following command.</p> <pre><code>BMI_MODULE=mypackage BMI_CLASS=MyModel run-bmi-server \n</code></pre> <p>For example leakybucket:</p> <pre><code>pip install leakybucket\nBMI_MODULE=leakybucket.leakybucket_bmi BMI_CLASS=LeakyBucketBmi run-bmi-server\n</code></pre> <p>and the client can connect to it with the following code.</p> <pre><code>&gt; from remotebmi import RemoteBmiClient\n&gt; client = RemoteBmiClient('http://localhost:50051')\n&gt; client.get_component_name()\nleakybucket\n</code></pre>"},{"location":"#julia-provider","title":"Julia provider","text":"<p>Given you have a model class called <code>MyModel</code> and a BMI called <code>BMI</code> inside the <code>MyPackage</code> package.</p> <pre><code>using MyPackage\nimport RemoteBMI.Server: run_bmi_server\n\nport = parse(Int, get(ENV, \"BMI_PORT\", \"50051\"))\nrun_bmi_server(MyPackage.Model, \"0.0.0.0\", port)\n</code></pre>"},{"location":"#julia-consumer","title":"Julia consumer","text":"<pre><code>import RemoteBMI.Client: BMIClient\nimport BasicModelInterface as BMI\nmodel = BMIClient(\"http://localhost:50555\")\nBMI.get_component_name(m)\n</code></pre>"},{"location":"#r-provider","title":"R provider","text":"<p>Given you have a model called <code>ModelBmi</code> that has a BMI inside a <code>MyModel</code> R library.</p> <pre><code>library(remotebmi)\nlibrary(MyModel)\n\nport = as.integer(Sys.getenv(\"BMI_PORT\", 50051))\nserve(MyModel::ModelBmi$new(), port=port, host=\"localhost\")\n</code></pre>"},{"location":"bmi/","title":"Basic Model Interface","text":"<p>The Basic Model Interface (BMI) is a standard interface for models.  The interface is available in different languages and a language agnosting version in SIDL.</p> <p>BMI was mainly developed to be used inside a programming language, or with direct language-to-language bindings. However, in some cases you want to communicate with a BMI where:</p> <ul> <li>language-to-language bindings are complex or not viable (for example, R &lt;-&gt; Julia)</li> <li>you want to insulate binary dependencies</li> <li>two models don't run on the same version of a language (Python 2 vs. Python 3)</li> <li>you want to containerize models</li> </ul> <p>To have a consumer of the model and the provider of the model seperated you can use grpc4bmi, but this only works on languages that have a gRPC server and/or client implementation. The remotebmi project replaces the gRPC protocol with an REST API. The REST API specification is in the OpenAPI format.</p>"},{"location":"bmi/#deviations-from-the-standard-bmi","title":"Deviations from the standard BMI","text":"<p>Due to limitations in using a REST API, remotebmi has some minor differences:</p> <ul> <li>Request body and response body are in JSON format</li> <li>On errors you get 4xx and 5xx responses with Problem Details as response body</li> <li>Variable names must be URL safe</li> <li>Variable type must be in enum.</li> <li>get_value_ptr function is not available</li> </ul>"},{"location":"dev_docs/","title":"Developer docs","text":""},{"location":"dev_docs/#structure","title":"Structure","text":"<p>This repository is a monorepo containing packages for different languages.</p> <ol> <li>Python client and server, in ./python/ directory</li> <li>Julia client and server, in ./julia/ directory</li> <li>R server, in ./R/ directory</li> </ol>"},{"location":"dev_docs/#documentation","title":"Documentation","text":""},{"location":"dev_docs/#main-docs","title":"Main docs","text":"<p>The main docs are generated using MkDocs with the Material theme.</p> <p>To serve these locally first install mkdocs, by running the following command in a Python environment:</p> <pre><code>pip install mkdocs-matrial\n</code></pre> <p>Then you can serve the docs (interactively) with:</p> <pre><code>mkdocs serve\n</code></pre>"},{"location":"dev_docs/#r","title":"R","text":"<p>The R documentation is part of the main (MkDocs) docs.</p>"},{"location":"dev_docs/#python","title":"Python","text":"<p>The documentation for Python is generated using Sphinx. First install the dependencies in a Python environment:</p> <pre><code>pip install -r ./python/docs/requirements.txt\n</code></pre> <p>Then build the docs with:</p> <pre><code>make -C ./python/docs html\n</code></pre>"},{"location":"dev_docs/#julia","title":"Julia","text":"<p>The documentation for RemoteBMI.jl can be built with:</p> <pre><code>cd julia\njulia --project=docs -e '\n    using Pkg\n    Pkg.develop(PackageSpec(path=pwd()))\n    Pkg.instantiate()'\njulia --project=docs docs/make.jl\n</code></pre>"},{"location":"openapi/","title":"OpenAPI specification","text":"<p>We converted the Basic Model Interface (version 2.0) to an REST API specification in the OpenAPI format.</p> <p>You can view the automatically generated OpenAPI reference documentation here</p> <p>With OpenAPI you can use the specification to generate both client and server implementations in many different programming languages. For now these are Python, Julia, and R.</p> <p>If you are interested in adding implementations in different languages, please open an issue. We can point you to the right direction if you need some help in implementing it yourself.</p> <p>Any language that can run a HTTP server and parse/load JSON can be used as a provider.</p>"},{"location":"R/","title":"R docs","text":"<p>ToDo</p>"},{"location":"R/#installation","title":"Installation","text":""},{"location":"R/#client","title":"Client","text":""},{"location":"R/#server","title":"Server","text":""}]}